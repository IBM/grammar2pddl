{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using AI planning to explore data science pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import sys\n",
    "import os\n",
    "import types\n",
    "\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), \"../grammar2lale\")))\n",
    "\n",
    "# Clean output directory where we store planning and result files\n",
    "os.system('rm -rf ../output')\n",
    "os.system('mkdir -p ../output')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Start with a Data Science grammar, in EBNF format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This is the grammar file we will use\n",
    "GRAMMAR_FILE=\"../grammar/dsgrammar-subset-sklearn.bnf\"\n",
    "\n",
    "# Copy grammar to the output directory\n",
    "os.system(\"cp \" + GRAMMAR_FILE + \" ../output/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Convert the grammar into an HTN domain and problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating HTN specification from grammar\n",
      "Printing HTN domain\n"
     ]
    }
   ],
   "source": [
    "from grammar2lale import Grammar2Lale\n",
    "\n",
    "# Generate HTN specifications\n",
    "G2L = Grammar2Lale(grammar_file=GRAMMAR_FILE)\n",
    "with open(\"../output/domain.htn\", \"w\") as f:\n",
    "    f.write(G2L.htn_domain);\n",
    "with open(\"../output/problem.htn\", \"w\") as f:\n",
    "    f.write(G2L.htn_problem);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Use https://github.com/ronwalf/HTN-Translation to translate to a PDDL task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1411136b82d499486dc1a849cb735bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=10, description='num_pipelines', min=1), SelectMultiple(description='Seaâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import re\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "import ipywidgets as widgets\n",
    "\n",
    "# as a safety step, setting costs to 0 for any parts of the grammar that are non-identifiers (e.g., parens, etc.)\n",
    "for token in G2L.htn.mapping:\n",
    "    if not re.match('^[_a-zA-Z]', str(token)):\n",
    "        G2L.costs[token] = 0\n",
    "        \n",
    "# prepare the list of possible constraints\n",
    "constraint_options = G2L.get_selectable_constraints()\n",
    "constraint_options.sort()    \n",
    "\n",
    "# prepare a constraint selection form\n",
    "interact_pipeline_params=interact.options(manual=True, manual_name='Generate PDDL')\n",
    "\n",
    "\n",
    "pipelines = []\n",
    "NUM_PIPELINES = 10\n",
    "CONSTRAINTS = []\n",
    "\n",
    "\n",
    "# This is the function that handles the constraint selection\n",
    "@interact_pipeline_params(num_pipelines=widgets.IntSlider(value=10, min=1, max=100), \n",
    "                          constraints=widgets.SelectMultiple(options=constraint_options,\n",
    "                                           description='Search constraints',\n",
    "                                           rows=min(20, len(constraint_options))))\n",
    "def select_pipeline_gen_params(num_pipelines, constraints):\n",
    "    global pipelines\n",
    "    global NUM_PIPELINES\n",
    "    global CONSTRAINTS\n",
    "    NUM_PIPELINES = num_pipelines\n",
    "    CONSTRAINTS = list(constraints)\n",
    "    G2L.create_pddl_task(NUM_PIPELINES, CONSTRAINTS)\n",
    "    with open(\"../output/domain.pddl\", \"w\") as f:\n",
    "        f.write(G2L.last_task['domain'])\n",
    "    with open(\"../output/problem.pddl\", \"w\") as f:\n",
    "        f.write(G2L.last_task['problem'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Use a planner to solve the planning task (in this case, kstar: https://github.com/ctpelok77/kstar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running the planner...\n",
      "Created domain file in /tmp/37fe183a-481d-4ebd-9462-d5fb05e1f383/domain.pddl\n",
      "Created problem file in /tmp/37fe183a-481d-4ebd-9462-d5fb05e1f383/problem.pddl\n",
      "Running kstar /tmp/37fe183a-481d-4ebd-9462-d5fb05e1f383/domain.pddl /tmp/37fe183a-481d-4ebd-9462-d5fb05e1f383/problem.pddl --search \"kstar(blind(),k=50,json_file_to_dump=result.json)\"\n",
      "Plans returned after 0.14537286758422852 seconds.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "G2L.run_pddl_planner()\n",
    "with open(\"../output/first_planner_call.json\", \"w\") as f:\n",
    "    f.write(json.dumps(G2L.last_planner_object, indent=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Translate plans to LALE (https://github.com/IBM/lale) Data Science pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Translating plans to LALE pipelines.\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-24c0032c6a2a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Translate to pipelines\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mpipelines\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mG2L\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranslate_to_pipelines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mNUM_PIPELINES\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpipeline_optimizer\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPipelineOptimizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatasets\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mload_iris\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/software/Challenges/planning4ds/opensourcing/grammar2lale/grammar2lale.py\u001b[0m in \u001b[0;36mtranslate_to_pipelines\u001b[0;34m(self, num_pipelines)\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Translating plans to LALE pipelines.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0minv_mapping\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhtn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvert_mapping\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m         \u001b[0mallplans\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mplan_to_pipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mplan\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minv_mapping\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplan_actions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mplan\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplan_tokens\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mplan\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minv_mapping\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplan\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'cost'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mplan\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlast_planner_object\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'plans'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m         \u001b[0mselected_plans\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m         \u001b[0mretplans\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "# Translate to pipelines\n",
    "pipelines = G2L.translate_to_pipelines(NUM_PIPELINES)\n",
    "\n",
    "from pipeline_optimizer import PipelineOptimizer\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "from lale.helpers import to_graphviz\n",
    "from lale.lib.sklearn import *\n",
    "from lale.lib.lale import ConcatFeatures as Concat\n",
    "from lale.lib.lale import NoOp\n",
    "from lale.lib.sklearn import KNeighborsClassifier as KNN\n",
    "from lale.lib.sklearn import OneHotEncoder as OneHotEnc\n",
    "from lale.lib.sklearn import Nystroem\n",
    "from lale.lib.sklearn import PCA\n",
    "\n",
    "optimizer = PipelineOptimizer(load_iris(return_X_y=True))\n",
    "# instantiate LALE objects from pipeline definitions\n",
    "LALE_pipelines = [optimizer.to_lale_pipeline(p) for p in pipelines]\n",
    "\n",
    "# Display selected pipeline\n",
    "def show_pipeline(pipeline):\n",
    "    print(\"Displaying pipeline \" + pipeline['id'] + \", with cost \" + str(pipeline['score']))\n",
    "    print(pipeline['pipeline'])\n",
    "    print('==================================================================================')\n",
    "    print()\n",
    "    print()\n",
    "    print()\n",
    "    display(to_graphviz(pipeline['lale_pipeline']))\n",
    "\n",
    "display_pipelines = [[p['pipeline'], p] for p in LALE_pipelines]    \n",
    "    \n",
    "interact(show_pipeline, pipeline=display_pipelines)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Run one of the pipelines on sample data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Train hyperparameters and evaluate the resulting LALE pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_pipelines, dropped_pipelines = optimizer.evaluate_and_train_pipelines(pipelines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import HTML\n",
    "from tabulate import tabulate\n",
    "from lale.pretty_print import to_string\n",
    "\n",
    "def show_pipeline_accuracy(tp):\n",
    "    pipeline_table = [[to_string(p['trained_pipeline']).replace('\\n', '<br/>'), str(p['best_accuracy'])] for p in tp]\n",
    "    display(HTML(tabulate(pipeline_table, headers=['Pipeline', 'Accuracy'], tablefmt='html')))\n",
    "\n",
    "\n",
    "show_pipeline_accuracy(trained_pipelines)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Use pipeline accuracy to compute new PDDL action costs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feedback = optimizer.get_feedback(trained_pipelines)\n",
    "G2L.feedback(feedback)\n",
    "costs_table = [[str(k), G2L.costs[k]] for k in G2L.costs.keys()]\n",
    "display(HTML(tabulate(costs_table, headers=['Pipeline element', 'Computed cost'], tablefmt='html')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Invoke planner again on updated PDDL task and translate to pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_pipelines = G2L.get_plans(num_pipelines=NUM_PIPELINES, constraints=CONSTRAINTS)\n",
    "\n",
    "with open('../output/domain_after_feedback.pddl', 'w') as f:\n",
    "    f.write(G2L.last_task['domain'])\n",
    "with open('../output/problem_after_feedback.pddl', 'w') as f:\n",
    "    f.write(G2L.last_task['problem'])\n",
    "with open('../output/second_planner_call.json', 'w') as f:\n",
    "    f.write(json.dumps(G2L.last_planner_object, indent=3))\n",
    "\n",
    "new_pipeline_table = [[pipelines[idx]['pipeline'], new_pipelines[idx]['pipeline']] for idx in range(min(len(pipelines), len(new_pipelines)))]\n",
    "display(HTML(tabulate(new_pipeline_table, headers=['First iteration', 'After feedback'], tablefmt='html')))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
