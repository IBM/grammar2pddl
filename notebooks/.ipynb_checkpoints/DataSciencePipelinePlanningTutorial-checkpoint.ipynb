{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "agreed-saturn",
   "metadata": {},
   "source": [
    "# Using AI planning to explore data science pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "domestic-panic",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import sys\n",
    "import os\n",
    "import types\n",
    "\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), \"../grammar2lale\")))\n",
    "\n",
    "# Clean output directory where we store planning and result files\n",
    "os.system('rm -rf ../output')\n",
    "os.system('mkdir -p ../output')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "promising-bonus",
   "metadata": {},
   "source": [
    "## 1. Start with a Data Science grammar, in EBNF format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "standing-unknown",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This is the grammar file we will use\n",
    "GRAMMAR_FILE=\"../grammar/dsgrammar-subset-sklearn.bnf\"\n",
    "\n",
    "# Copy grammar to the output directory\n",
    "os.system(\"cp \" + GRAMMAR_FILE + \" ../output/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wrong-bullet",
   "metadata": {},
   "source": [
    "## 2. Convert the grammar into an HTN domain and problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "satisfied-spouse",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating HTN specification from grammar\n",
      "Printing HTN domain\n"
     ]
    }
   ],
   "source": [
    "from grammar2lale.grammar2lale import Grammar2Lale\n",
    "\n",
    "# Generate HTN specifications\n",
    "G2L = Grammar2Lale(grammar_file=GRAMMAR_FILE)\n",
    "with open(\"../output/domain.htn\", \"w\") as f:\n",
    "    f.write(G2L.htn_domain);\n",
    "with open(\"../output/problem.htn\", \"w\") as f:\n",
    "    f.write(G2L.htn_problem);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "infrared-knife",
   "metadata": {},
   "source": [
    "## 3. Use https://github.com/ronwalf/HTN-Translation to translate to a PDDL task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "baking-torture",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef6a3e9f785e4558a8f6eb60cbb3c1c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=10, description='num_pipelines', min=1), SelectMultiple(description='Sea…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import re\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "import ipywidgets as widgets\n",
    "\n",
    "# as a safety step, setting costs to 0 for any parts of the grammar that are non-identifiers (e.g., parens, etc.)\n",
    "for token in G2L.htn.mapping:\n",
    "    if not re.match('^[_a-zA-Z]', str(token)):\n",
    "        G2L.costs[token] = 0\n",
    "        \n",
    "# prepare the list of possible constraints\n",
    "constraint_options = G2L.get_selectable_constraints()\n",
    "constraint_options.sort()    \n",
    "\n",
    "# prepare a constraint selection form\n",
    "interact_pipeline_params=interact.options(manual=True, manual_name='Generate PDDL')\n",
    "\n",
    "\n",
    "pipelines = []\n",
    "NUM_PIPELINES = 10\n",
    "CONSTRAINTS = []\n",
    "\n",
    "\n",
    "# This is the function that handles the constraint selection\n",
    "@interact_pipeline_params(num_pipelines=widgets.IntSlider(value=10, min=1, max=100), \n",
    "                          constraints=widgets.SelectMultiple(options=constraint_options,\n",
    "                                           description='Search constraints',\n",
    "                                           rows=min(20, len(constraint_options))))\n",
    "def select_pipeline_gen_params(num_pipelines, constraints):\n",
    "    global pipelines\n",
    "    global NUM_PIPELINES\n",
    "    global CONSTRAINTS\n",
    "    NUM_PIPELINES = num_pipelines\n",
    "    CONSTRAINTS = list(constraints)\n",
    "    G2L.create_pddl_task(NUM_PIPELINES, CONSTRAINTS)\n",
    "    with open(\"../output/domain.pddl\", \"w\") as f:\n",
    "        f.write(G2L.last_task['domain'])\n",
    "    with open(\"../output/problem.pddl\", \"w\") as f:\n",
    "        f.write(G2L.last_task['problem'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "theoretical-chicken",
   "metadata": {},
   "source": [
    "## 4. Use a planner to solve the planning task (in this case, kstar: https://github.com/ctpelok77/kstar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "critical-reunion",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running the planner...\n",
      "Created domain file in /tmp/df55b130-3b2b-4185-b50c-7b0228a2df58/domain.pddl\n",
      "Created problem file in /tmp/df55b130-3b2b-4185-b50c-7b0228a2df58/problem.pddl\n",
      "Running kstar /tmp/df55b130-3b2b-4185-b50c-7b0228a2df58/domain.pddl /tmp/df55b130-3b2b-4185-b50c-7b0228a2df58/problem.pddl --search \"kstar(blind(),k=50,json_file_to_dump=result.json)\"\n",
      "Plans returned after 1.2340526580810547 seconds.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "G2L.run_pddl_planner()\n",
    "with open(\"../output/first_planner_call.json\", \"w\") as f:\n",
    "    f.write(json.dumps(G2L.last_planner_object, indent=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "editorial-jungle",
   "metadata": {},
   "source": [
    "## 5. Translate plans to LALE (https://github.com/IBM/lale) Data Science pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "derived-protocol",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Translating plans to LALE pipelines.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15aa158f387c4ecfae3918f963d9faf4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='pipeline', options=(['Normalizer() >> DecisionTreeClassifier()', {…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.show_pipeline(pipeline)>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Translate to pipelines\n",
    "pipelines = G2L.translate_to_pipelines(NUM_PIPELINES)\n",
    "\n",
    "from pipeline_optimizer import PipelineOptimizer\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "from lale.helpers import to_graphviz\n",
    "from lale.lib.sklearn import *\n",
    "from lale.lib.lale import ConcatFeatures as Concat\n",
    "from lale.lib.lale import NoOp\n",
    "from lale.lib.sklearn import KNeighborsClassifier as KNN\n",
    "from lale.lib.sklearn import OneHotEncoder as OneHotEnc\n",
    "from lale.lib.sklearn import Nystroem\n",
    "from lale.lib.sklearn import PCA\n",
    "\n",
    "optimizer = PipelineOptimizer(load_iris(return_X_y=True))\n",
    "# instantiate LALE objects from pipeline definitions\n",
    "LALE_pipelines = [optimizer.to_lale_pipeline(p) for p in pipelines]\n",
    "\n",
    "# Display selected pipeline\n",
    "def show_pipeline(pipeline):\n",
    "    print(\"Displaying pipeline \" + pipeline['id'] + \", with cost \" + str(pipeline['score']))\n",
    "    print(pipeline['pipeline'])\n",
    "    print('==================================================================================')\n",
    "    print()\n",
    "    print()\n",
    "    print()\n",
    "    display(to_graphviz(pipeline['lale_pipeline']))\n",
    "\n",
    "display_pipelines = [[p['pipeline'], p] for p in LALE_pipelines]    \n",
    "    \n",
    "interact(show_pipeline, pipeline=display_pipelines)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hungarian-pierce",
   "metadata": {},
   "source": [
    "## 6. Run one of the pipelines on sample data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "heated-hawaiian",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "studied-bangkok",
   "metadata": {},
   "source": [
    "## 7. Train hyperparameters and evaluate the resulting LALE pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "permanent-richmond",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plan 1/10\n",
      "Starting to optimize Normalizer() >> DecisionTreeClassifier()\n",
      "100%|██████████| 20/20 [00:06<00:00,  3.03trial/s, best loss: -0.8699999999999999]\n",
      "Fit completed.\n",
      "Predict completed.\n",
      "Best accuracy: 0.9333333333333333\n",
      "Completed optimization for Normalizer() >> DecisionTreeClassifier()\n",
      "Plan 2/10\n",
      "Starting to optimize StandardScaler() >> DecisionTreeClassifier()\n",
      "100%|██████████| 20/20 [00:07<00:00,  2.57trial/s, best loss: -0.9199999999999999]\n",
      "Fit completed.\n",
      "Predict completed.\n",
      "Best accuracy: 0.96\n",
      "Completed optimization for StandardScaler() >> DecisionTreeClassifier()\n",
      "Plan 3/10\n",
      "Starting to optimize RobustScaler() >> DecisionTreeClassifier()\n",
      "100%|██████████| 20/20 [00:06<00:00,  2.91trial/s, best loss: -0.9]               \n",
      "Fit completed.\n",
      "Predict completed.\n",
      "Best accuracy: 0.96\n",
      "Completed optimization for RobustScaler() >> DecisionTreeClassifier()\n",
      "Plan 4/10\n",
      "Starting to optimize MinMaxScaler() >> DecisionTreeClassifier()\n",
      "100%|██████████| 20/20 [00:06<00:00,  2.86trial/s, best loss: -0.9199999999999999]\n",
      "Fit completed.\n",
      "Predict completed.\n",
      "Best accuracy: 0.96\n",
      "Completed optimization for MinMaxScaler() >> DecisionTreeClassifier()\n",
      "Plan 5/10\n",
      "Starting to optimize PCA() >> DecisionTreeClassifier()\n",
      "100%|██████████| 20/20 [00:08<00:00,  2.40trial/s, best loss: -0.8800000000000001]\n",
      "Fit completed.\n",
      "Predict completed.\n",
      "Best accuracy: 0.9466666666666667\n",
      "Completed optimization for PCA() >> DecisionTreeClassifier()\n",
      "Plan 6/10\n",
      "Starting to optimize Normalizer() >> Normalizer() >> DecisionTreeClassifier()\n",
      "100%|██████████| 20/20 [00:07<00:00,  2.65trial/s, best loss: -0.89]\n",
      "Fit completed.\n",
      "Predict completed.\n",
      "Best accuracy: 0.9466666666666667\n",
      "Completed optimization for Normalizer() >> Normalizer() >> DecisionTreeClassifier()\n",
      "Plan 7/10\n",
      "Starting to optimize Normalizer() >> StandardScaler() >> DecisionTreeClassifier()\n",
      "100%|██████████| 20/20 [00:09<00:00,  2.15trial/s, best loss: -0.9299999999999999]\n",
      "Fit completed.\n",
      "Predict completed.\n",
      "Best accuracy: 0.98\n",
      "Completed optimization for Normalizer() >> StandardScaler() >> DecisionTreeClassifier()\n",
      "Plan 8/10\n",
      "Starting to optimize Normalizer() >> MinMaxScaler() >> DecisionTreeClassifier()\n",
      "100%|██████████| 20/20 [00:08<00:00,  2.49trial/s, best loss: -0.9]              \n",
      "Fit completed.\n",
      "Predict completed.\n",
      "Best accuracy: 0.9333333333333333\n",
      "Completed optimization for Normalizer() >> MinMaxScaler() >> DecisionTreeClassifier()\n",
      "Plan 9/10\n",
      "Starting to optimize Normalizer() >> RobustScaler() >> DecisionTreeClassifier()\n",
      "100%|██████████| 20/20 [00:09<00:00,  2.10trial/s, best loss: -0.9099999999999999]\n",
      "Fit completed.\n",
      "Predict completed.\n",
      "Best accuracy: 0.92\n",
      "Completed optimization for Normalizer() >> RobustScaler() >> DecisionTreeClassifier()\n",
      "Plan 10/10\n",
      "Starting to optimize StandardScaler() >> Normalizer() >> DecisionTreeClassifier()\n",
      "100%|██████████| 20/20 [00:08<00:00,  2.34trial/s, best loss: -0.9400000000000001]\n",
      "Fit completed.\n",
      "Predict completed.\n",
      "Best accuracy: 0.9866666666666667\n",
      "Completed optimization for StandardScaler() >> Normalizer() >> DecisionTreeClassifier()\n"
     ]
    }
   ],
   "source": [
    "trained_pipelines, dropped_pipelines = optimizer.evaluate_and_train_pipelines(pipelines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "oriental-boards",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead>\n",
       "<tr><th>Pipeline                                                                                                                                                                                                                                                                                                                                                                                                       </th><th style=\"text-align: right;\">  Accuracy</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>from lale.lib.lale import Hyperopt<br/>from sklearn.preprocessing import Normalizer<br/>from sklearn.tree import DecisionTreeClassifier<br/>import lale<br/><br/>lale.wrap_imported_operators()<br/>pipeline = Hyperopt(<br/>    estimator=Normalizer() >> DecisionTreeClassifier(),<br/>    max_evals=20,<br/>    scoring=\"r2\",<br/>)                                                                         </td><td style=\"text-align: right;\">  0.933333</td></tr>\n",
       "<tr><td>from lale.lib.lale import Hyperopt<br/>from sklearn.preprocessing import StandardScaler<br/>from sklearn.tree import DecisionTreeClassifier<br/>import lale<br/><br/>lale.wrap_imported_operators()<br/>pipeline = Hyperopt(<br/>    estimator=StandardScaler() >> DecisionTreeClassifier(),<br/>    max_evals=20,<br/>    scoring=\"r2\",<br/>)                                                                 </td><td style=\"text-align: right;\">  0.96    </td></tr>\n",
       "<tr><td>from lale.lib.lale import Hyperopt<br/>from sklearn.preprocessing import RobustScaler<br/>from sklearn.tree import DecisionTreeClassifier<br/>import lale<br/><br/>lale.wrap_imported_operators()<br/>pipeline = Hyperopt(<br/>    estimator=RobustScaler() >> DecisionTreeClassifier(),<br/>    max_evals=20,<br/>    scoring=\"r2\",<br/>)                                                                     </td><td style=\"text-align: right;\">  0.96    </td></tr>\n",
       "<tr><td>from lale.lib.lale import Hyperopt<br/>from sklearn.preprocessing import MinMaxScaler<br/>from sklearn.tree import DecisionTreeClassifier<br/>import lale<br/><br/>lale.wrap_imported_operators()<br/>pipeline = Hyperopt(<br/>    estimator=MinMaxScaler() >> DecisionTreeClassifier(),<br/>    max_evals=20,<br/>    scoring=\"r2\",<br/>)                                                                     </td><td style=\"text-align: right;\">  0.96    </td></tr>\n",
       "<tr><td>from lale.lib.lale import Hyperopt<br/>from sklearn.decomposition import PCA<br/>from sklearn.tree import DecisionTreeClassifier<br/>import lale<br/><br/>lale.wrap_imported_operators()<br/>pipeline = Hyperopt(<br/>    estimator=PCA() >> DecisionTreeClassifier(), max_evals=20, scoring=\"r2\"<br/>)                                                                                                        </td><td style=\"text-align: right;\">  0.946667</td></tr>\n",
       "<tr><td>from lale.lib.lale import Hyperopt<br/>from sklearn.preprocessing import Normalizer<br/>from sklearn.tree import DecisionTreeClassifier<br/>import lale<br/><br/>lale.wrap_imported_operators()<br/>pipeline = Hyperopt(<br/>    estimator=Normalizer() >> Normalizer() >> DecisionTreeClassifier(),<br/>    max_evals=20,<br/>    scoring=\"r2\",<br/>)                                                         </td><td style=\"text-align: right;\">  0.946667</td></tr>\n",
       "<tr><td>from lale.lib.lale import Hyperopt<br/>from sklearn.preprocessing import Normalizer<br/>from sklearn.preprocessing import StandardScaler<br/>from sklearn.tree import DecisionTreeClassifier<br/>import lale<br/><br/>lale.wrap_imported_operators()<br/>pipeline = Hyperopt(<br/>    estimator=Normalizer() >> StandardScaler() >> DecisionTreeClassifier(),<br/>    max_evals=20,<br/>    scoring=\"r2\",<br/>)</td><td style=\"text-align: right;\">  0.98    </td></tr>\n",
       "<tr><td>from lale.lib.lale import Hyperopt<br/>from sklearn.preprocessing import Normalizer<br/>from sklearn.preprocessing import MinMaxScaler<br/>from sklearn.tree import DecisionTreeClassifier<br/>import lale<br/><br/>lale.wrap_imported_operators()<br/>pipeline = Hyperopt(<br/>    estimator=Normalizer() >> MinMaxScaler() >> DecisionTreeClassifier(),<br/>    max_evals=20,<br/>    scoring=\"r2\",<br/>)    </td><td style=\"text-align: right;\">  0.933333</td></tr>\n",
       "<tr><td>from lale.lib.lale import Hyperopt<br/>from sklearn.preprocessing import Normalizer<br/>from sklearn.preprocessing import RobustScaler<br/>from sklearn.tree import DecisionTreeClassifier<br/>import lale<br/><br/>lale.wrap_imported_operators()<br/>pipeline = Hyperopt(<br/>    estimator=Normalizer() >> RobustScaler() >> DecisionTreeClassifier(),<br/>    max_evals=20,<br/>    scoring=\"r2\",<br/>)    </td><td style=\"text-align: right;\">  0.92    </td></tr>\n",
       "<tr><td>from lale.lib.lale import Hyperopt<br/>from sklearn.preprocessing import StandardScaler<br/>from sklearn.preprocessing import Normalizer<br/>from sklearn.tree import DecisionTreeClassifier<br/>import lale<br/><br/>lale.wrap_imported_operators()<br/>pipeline = Hyperopt(<br/>    estimator=StandardScaler() >> Normalizer() >> DecisionTreeClassifier(),<br/>    max_evals=20,<br/>    scoring=\"r2\",<br/>)</td><td style=\"text-align: right;\">  0.986667</td></tr>\n",
       "</tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import HTML\n",
    "from tabulate import tabulate\n",
    "from lale.pretty_print import to_string\n",
    "\n",
    "def show_pipeline_accuracy(tp):\n",
    "    pipeline_table = [[to_string(p['trained_pipeline']).replace('\\n', '<br/>'), str(p['best_accuracy'])] for p in tp]\n",
    "    display(HTML(tabulate(pipeline_table, headers=['Pipeline', 'Accuracy'], tablefmt='html')))\n",
    "\n",
    "\n",
    "show_pipeline_accuracy(trained_pipelines)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "powered-secretary",
   "metadata": {},
   "source": [
    "## 8. Use pipeline accuracy to compute new PDDL action costs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "numeric-alexandria",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead>\n",
       "<tr><th>Pipeline element        </th><th style=\"text-align: right;\">  Computed cost</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>Normalizer()            </td><td style=\"text-align: right;\">             78</td></tr>\n",
       "<tr><td>>>                      </td><td style=\"text-align: right;\">              0</td></tr>\n",
       "<tr><td>DecisionTreeClassifier()</td><td style=\"text-align: right;\">             76</td></tr>\n",
       "<tr><td>StandardScaler()        </td><td style=\"text-align: right;\">             58</td></tr>\n",
       "<tr><td>RobustScaler()          </td><td style=\"text-align: right;\">             85</td></tr>\n",
       "<tr><td>MinMaxScaler()          </td><td style=\"text-align: right;\">             80</td></tr>\n",
       "<tr><td>PCA()                   </td><td style=\"text-align: right;\">             80</td></tr>\n",
       "<tr><td>(                       </td><td style=\"text-align: right;\">              0</td></tr>\n",
       "<tr><td>)                       </td><td style=\"text-align: right;\">              0</td></tr>\n",
       "<tr><td>&                       </td><td style=\"text-align: right;\">              0</td></tr>\n",
       "<tr><td>                        </td><td style=\"text-align: right;\">              0</td></tr>\n",
       "</tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "feedback = optimizer.get_feedback(trained_pipelines)\n",
    "G2L.feedback(feedback)\n",
    "costs_table = [[str(k), G2L.costs[k]] for k in G2L.costs.keys()]\n",
    "display(HTML(tabulate(costs_table, headers=['Pipeline element', 'Computed cost'], tablefmt='html')))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "norman-pharmaceutical",
   "metadata": {},
   "source": [
    "## 9. Invoke planner again on updated PDDL task and translate to pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "balanced-frame",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating PDDL description...\n",
      "Obtaining 10 plans with constraints ['DecisionTreeClassifier()']\n",
      "Running the planner...\n",
      "Created domain file in /tmp/ff4b0a5b-6cd9-4099-8183-c2d74a5f72b3/domain.pddl\n",
      "Created problem file in /tmp/ff4b0a5b-6cd9-4099-8183-c2d74a5f72b3/problem.pddl\n",
      "Running kstar /tmp/ff4b0a5b-6cd9-4099-8183-c2d74a5f72b3/domain.pddl /tmp/ff4b0a5b-6cd9-4099-8183-c2d74a5f72b3/problem.pddl --search \"kstar(blind(),k=50,json_file_to_dump=result.json)\"\n",
      "Plans returned after 0.9109635353088379 seconds.\n",
      "Translating plans to LALE pipelines.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead>\n",
       "<tr><th>First iteration                                             </th><th>After feedback                                                  </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>Normalizer() >> DecisionTreeClassifier()                    </td><td>StandardScaler() >> DecisionTreeClassifier()                    </td></tr>\n",
       "<tr><td>StandardScaler() >> DecisionTreeClassifier()                </td><td>Normalizer() >> DecisionTreeClassifier()                        </td></tr>\n",
       "<tr><td>RobustScaler() >> DecisionTreeClassifier()                  </td><td>MinMaxScaler() >> DecisionTreeClassifier()                      </td></tr>\n",
       "<tr><td>MinMaxScaler() >> DecisionTreeClassifier()                  </td><td>PCA() >> DecisionTreeClassifier()                               </td></tr>\n",
       "<tr><td>PCA() >> DecisionTreeClassifier()                           </td><td>RobustScaler() >> DecisionTreeClassifier()                      </td></tr>\n",
       "<tr><td>Normalizer() >> Normalizer() >> DecisionTreeClassifier()    </td><td>StandardScaler() >> StandardScaler() >> DecisionTreeClassifier()</td></tr>\n",
       "<tr><td>Normalizer() >> StandardScaler() >> DecisionTreeClassifier()</td><td>StandardScaler() >> Normalizer() >> DecisionTreeClassifier()    </td></tr>\n",
       "<tr><td>Normalizer() >> MinMaxScaler() >> DecisionTreeClassifier()  </td><td>Normalizer() >> StandardScaler() >> DecisionTreeClassifier()    </td></tr>\n",
       "<tr><td>Normalizer() >> RobustScaler() >> DecisionTreeClassifier()  </td><td>StandardScaler() >> MinMaxScaler() >> DecisionTreeClassifier()  </td></tr>\n",
       "<tr><td>StandardScaler() >> Normalizer() >> DecisionTreeClassifier()</td><td>MinMaxScaler() >> StandardScaler() >> DecisionTreeClassifier()  </td></tr>\n",
       "</tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "new_pipelines = G2L.get_plans(num_pipelines=NUM_PIPELINES, constraints=CONSTRAINTS)\n",
    "\n",
    "with open('../output/domain_after_feedback.pddl', 'w') as f:\n",
    "    f.write(G2L.last_task['domain'])\n",
    "with open('../output/problem_after_feedback.pddl', 'w') as f:\n",
    "    f.write(G2L.last_task['problem'])\n",
    "with open('../output/second_planner_call.json', 'w') as f:\n",
    "    f.write(json.dumps(G2L.last_planner_object, indent=3))\n",
    "\n",
    "new_pipeline_table = [[pipelines[idx]['pipeline'], new_pipelines[idx]['pipeline']] for idx in range(min(len(pipelines), len(new_pipelines)))]\n",
    "display(HTML(tabulate(new_pipeline_table, headers=['First iteration', 'After feedback'], tablefmt='html')))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "medieval-consultation",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
